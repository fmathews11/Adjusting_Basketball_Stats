{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "master_column_names = ['date',\n",
    "                    'opp_name',\n",
    "                    'wl',\n",
    "                    'score',\n",
    "                    'opp_score',\n",
    "                    'fg',\n",
    "                    'fga',\n",
    "                    'fgpct',\n",
    "                    '3p',\n",
    "                    '3pa',\n",
    "                    '3ppct',\n",
    "                    'ft',\n",
    "                    'fta',\n",
    "                    'ftpct',\n",
    "                    'orb',\n",
    "                    'trb',\n",
    "                    'ast',\n",
    "                    'stl',\n",
    "                    'blk',\n",
    "                    'tov',\n",
    "                    'pf',\n",
    "                    'opp_fg',\n",
    "                    'opp_fga',\n",
    "                    'opp_fgpct',\n",
    "                    'opp_3p',\n",
    "                    'opp_3pa',\n",
    "                    'opp_3ppct',\n",
    "                    'opp_ft',\n",
    "                    'opp_fta',\n",
    "                    'opp_ftpct',\n",
    "                    'opp_orb',\n",
    "                    'opp_trb',\n",
    "                    'opp_ast',\n",
    "                    'opp_stl',\n",
    "                    'opp_blk',\n",
    "                    'opp_tov',\n",
    "                    'opp_pf',\n",
    "                    'team_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insantiate an empty dictionary\n",
    "team_name_id_dict = {}\n",
    "\n",
    "# URL for data from all schools\n",
    "all_schools_url = 'https://www.sports-reference.com/cbb/seasons/men/2023-school-stats.html'\n",
    "response = requests.get(all_schools_url, timeout = 10)\n",
    "soup = BeautifulSoup(response.content)\n",
    "# Find table ('tr')\n",
    "table = soup.findAll('tr')\n",
    "\n",
    "# Iterate through rows\n",
    "for row in table:\n",
    "    # Returns a None object if nothing is found\n",
    "    search = row.find('a',href = True)\n",
    "    # If we have something\n",
    "    if search:\n",
    "\n",
    "        # Extract the name and URL via string manipulation\n",
    "        url_suffix = str(search).split('\"')[1].replace(\".html\",\"\")\n",
    "        team_name = str(search).split(\">\")[1].replace(\"</a\",\"\").strip()\n",
    "        # Update the dictionary\n",
    "        team_name_id_dict[team_name] = url_suffix\n",
    "\n",
    "print(team_name_id_dict['Purdue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate empty data frame\n",
    "master_df = pd.DataFrame()\n",
    "# Create an iteration counter\n",
    "counter = 0\n",
    "# Create a random number between 100 and 300.  This is where the loop will pause\n",
    "# So as to not overload the site\n",
    "stop_to_rest_point = np.random.randint(20,100)\n",
    "\n",
    "url_prefix = 'https://www.sports-reference.com'\n",
    "\n",
    "# Iterate through the dictionary\n",
    "for team_name,url_suffix in tqdm(team_name_id_dict.items()):\n",
    "\n",
    "    full_url = f\"{url_prefix}{url_suffix}-gamelogs.html\"\n",
    "    temp_df = pd.read_html(full_url)[0]\n",
    "    # Surface-level data cleaning\n",
    "    temp_df.columns = [col2 if (col1.startswith('Unnamed') or col1 == \"School\") else f\"opp_{col2}\" for col1,col2 in temp_df.columns]\n",
    "    temp_df = temp_df.iloc[:,~temp_df.columns.str.startswith('Unnamed')].drop('G',axis = 1).dropna().query(\"Date != 'Date'\")\n",
    "    temp_df['team_name'] = team_name\n",
    "    temp_df.columns = master_column_names\n",
    "    # Appending the cleaned dataframe back to the master data frame\n",
    "    master_df = pd.concat([master_df,temp_df])\n",
    "\n",
    "    # Increment counter\n",
    "    counter +=1\n",
    "    # Sleep and save if we've reached our random number\n",
    "    if counter == stop_to_rest_point:\n",
    "\n",
    "        time.sleep(np.random.randint(60,120))\n",
    "        master_df.to_parquet('parquet_files/box_scores_sports_reference.gzip',compression='gzip')\n",
    "        continue\n",
    "    \n",
    "    # Sleep for 3 to 7 seconds\n",
    "    time.sleep(np.random.randint(3,7))\n",
    "\n",
    "master_df.to_parquet('parquet_files/box_scores_sports_reference.gzip',compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
