{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "master_column_names = ['date',\n",
    "                    'opp_name',\n",
    "                    'wl',\n",
    "                    'score',\n",
    "                    'opp_score',\n",
    "                    'fg',\n",
    "                    'fga',\n",
    "                    'fgpct',\n",
    "                    '3p',\n",
    "                    '3pa',\n",
    "                    '3ppct',\n",
    "                    'ft',\n",
    "                    'fta',\n",
    "                    'ftpct',\n",
    "                    'orb',\n",
    "                    'trb',\n",
    "                    'ast',\n",
    "                    'stl',\n",
    "                    'blk',\n",
    "                    'tov',\n",
    "                    'pf',\n",
    "                    'opp_fg',\n",
    "                    'opp_fga',\n",
    "                    'opp_fgpct',\n",
    "                    'opp_3p',\n",
    "                    'opp_3pa',\n",
    "                    'opp_3ppct',\n",
    "                    'opp_ft',\n",
    "                    'opp_fta',\n",
    "                    'opp_ftpct',\n",
    "                    'opp_orb',\n",
    "                    'opp_trb',\n",
    "                    'opp_ast',\n",
    "                    'opp_stl',\n",
    "                    'opp_blk',\n",
    "                    'opp_tov',\n",
    "                    'opp_pf',\n",
    "                    'team_name']\n",
    "\n",
    "url_prefix = 'https://www.sports-reference.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insantiate an empty dictionary\n",
    "team_name_id_dict = {}\n",
    "\n",
    "# URL for data from all schools\n",
    "all_schools_url = 'https://www.sports-reference.com/cbb/seasons/men/2023-school-stats.html'\n",
    "response = requests.get(all_schools_url, timeout = 10)\n",
    "soup = BeautifulSoup(response.content)\n",
    "# Find table ('tr')\n",
    "table = soup.findAll('tr')\n",
    "\n",
    "# Iterate through rows\n",
    "for row in table:\n",
    "    # Returns a None object if nothing is found\n",
    "    search = row.find('a',href = True)\n",
    "    # If we have something\n",
    "    if search:\n",
    "\n",
    "        # Extract the name and URL via string manipulation\n",
    "        url_suffix = str(search).split('\"')[1].replace(\".html\",\"\")\n",
    "        team_name = str(search).split(\">\")[1].replace(\"</a\",\"\").strip()\n",
    "        # Update the dictionary\n",
    "        team_name_id_dict[team_name] = url_suffix\n",
    "\n",
    "print(team_name_id_dict['Purdue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate empty data frame\n",
    "master_df = pd.DataFrame()\n",
    "# Create an iteration counter\n",
    "counter = 0\n",
    "# Create a random number between 100 and 300.  This is where the loop will pause\n",
    "# So as to not overload the site\n",
    "stop_to_rest_point = np.random.randint(20,100)\n",
    "\n",
    "\n",
    "# Iterate through the dictionary\n",
    "for team_name,url_suffix in tqdm(team_name_id_dict.items()):\n",
    "\n",
    "    full_url = f\"{url_prefix}{url_suffix}-gamelogs.html\"\n",
    "    temp_df = pd.read_html(full_url)[0]\n",
    "    # Surface-level data cleaning\n",
    "    temp_df.columns = [col2 if (col1.startswith('Unnamed') or col1 == \"School\") else f\"opp_{col2}\" for col1,col2 in temp_df.columns]\n",
    "    temp_df = temp_df.iloc[:,~temp_df.columns.str.startswith('Unnamed')].drop('G',axis = 1).dropna().query(\"Date != 'Date'\")\n",
    "    temp_df['team_name'] = team_name\n",
    "    temp_df.columns = master_column_names\n",
    "    # Appending the cleaned dataframe back to the master data frame\n",
    "    master_df = pd.concat([master_df,temp_df])\n",
    "\n",
    "    # Increment counter\n",
    "    counter +=1\n",
    "    # Sleep and save if we've reached our random number\n",
    "    if counter == stop_to_rest_point:\n",
    "\n",
    "        time.sleep(np.random.randint(60,120))\n",
    "        master_df.to_parquet('parquet_files/box_scores_sports_reference.gzip',compression='gzip')\n",
    "        continue\n",
    "    \n",
    "    # Sleep for 3 to 7 seconds\n",
    "    time.sleep(np.random.randint(3,7))\n",
    "\n",
    "master_df.to_parquet('parquet_files/box_scores_sports_reference.gzip',compression='gzip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual game box scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_game_uis = set()\n",
    "team_game_id_dict = {team:set() for team in team_name_id_dict.keys()}\n",
    "\n",
    "counter = 0\n",
    "stop_to_rest_point = np.random.randint(25,70)\n",
    "\n",
    "for team_name,team_url_section in tqdm(team_name_id_dict.items()):\n",
    "\n",
    "    url = f'{url_prefix}{team_url_section}{\"-gamelogs.html\"}'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Status code was {response.status_code} for {url}\")\n",
    "    \n",
    "    soup = BeautifulSoup(response.content)\n",
    "    table = soup.findAll(\"tr\")\n",
    "\n",
    "    for row in table:\n",
    "\n",
    "        search = row.find('a',href = True)\n",
    "        \n",
    "        if not search:\n",
    "            continue\n",
    "            \n",
    "        game_ui = str(search).split('>')[0].replace('<a href=\"/cbb/boxscores/',\"\").replace('.html\"',\"\")\n",
    "\n",
    "        # Games that were forfeitted end with '2023', so we want to remove those\n",
    "        if game_ui.endswith('2023'):\n",
    "            continue\n",
    "\n",
    "        all_game_uis.add(game_ui)\n",
    "        team_game_id_dict[team_name].add(game_ui)\n",
    " \n",
    "    counter +=1\n",
    "    if counter == stop_to_rest_point:\n",
    "\n",
    "        time.sleep(np.random.randint(60,120))\n",
    "        continue\n",
    "    \n",
    "    time.sleep(np.random.randint(2,7))\n",
    "\n",
    "# Save the dict as a pickle file\n",
    "with open('pickle_files/sports_reference_cbb_teams_and_game_uis.pickle','wb') as f:\n",
    "    pickle.dump(team_game_id_dict,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6222/6222 [1:18:15<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('pickle_files/game_ids_with_boxscores.pickle','rb') as f:\n",
    "        game_ui_boxscore_dict = pickle.load(f)\n",
    "\n",
    "counter = 0\n",
    "save_point = 100\n",
    "\n",
    "# Iterate through the game IDs\n",
    "for game_id, sub_dict in tqdm(game_ui_boxscore_dict.items()):\n",
    "\n",
    "    # Confirmed bad ID\n",
    "    if game_id == \"2022-11-29-20-oral-roberts\":\n",
    "         continue\n",
    "\n",
    "    # Skip if we've already gotten data for this game (list is not empty)\n",
    "    if sub_dict['raw_dataframes']:\n",
    "        continue\n",
    "\n",
    "    url = f\"{url_prefix}/cbb/boxscores/{game_id}.html\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Stop if status code is bad\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'Status code returned was {response.status_code} from URL {url}')\n",
    "    \n",
    "\n",
    "    soup = BeautifulSoup(response.content)\n",
    "    first_team = str(soup.find('title')).split('vs.')[0].replace('<title>',\"\").strip()\n",
    "    second_team = str(soup.find('title')).split(\"Box\")[0].split('vs.')[1].strip()\n",
    "    assert first_team,second_team in team_game_id_dict\n",
    "    sub_dict['first_team'] = first_team\n",
    "    sub_dict['second_team'] = second_team\n",
    "\n",
    "    # The last four dataframes of the 20+ returned are what we want\n",
    "    target_dfs = pd.read_html(response.text)[-4:]\n",
    "    sub_dict['raw_dataframes'].extend(target_dfs)\n",
    "    \n",
    "    counter += 1\n",
    "    if counter < save_point:\n",
    "\n",
    "        time.sleep(np.random.randint(3,5))\n",
    "        # Pickle it ever so often just in case something happens\n",
    "        with open('pickle_files/game_ids_with_boxscores.pickle','wb') as f:\n",
    "            pickle.dump(game_ui_boxscore_dict,f)\n",
    "        continue\n",
    "\n",
    "    time.sleep(np.random.randint(3,5))\n",
    "\n",
    "# Pickle it\n",
    "with open('pickle_files/game_ids_with_boxscores.pickle','wb') as f:\n",
    "    pickle.dump(game_ui_boxscore_dict,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
