{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from modules.functions import get_schedule,ids,create_home_and_away_simple_dataframe,BadStatusCodeError\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "ids = ids.loc[ids.link.notnull()].copy()\n",
    "%cd Adjusting_Basketball_Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_parquet('parquet_files/master_dataframe.gzip')\n",
    "#already_scraped_ids = set(master_df.Game_ID.unique().tolist())\n",
    "not_yet_played_ids = set()\n",
    "with open('pickle_files/forfeitted_game_ids.pickle','rb') as f:\n",
    "    forfeited_game_ids = pickle.load(f)\n",
    "already_scraped_ids = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "bad_requests_counter = 0\n",
    "\n",
    "for team in tqdm(ids.team.unique().tolist()):\n",
    "\n",
    "    scrape_counter = 0\n",
    "    time.sleep(np.random.randint(2,6))\n",
    "    temp_master_dict = get_schedule(team).drop_duplicates(subset=\"GAME_ID\").set_index(\"GAME_ID\").to_dict(orient = 'index')\n",
    "    quick_skip = True\n",
    "\n",
    "    for game_id,sub_dict in temp_master_dict.items():\n",
    "\n",
    "        game_id = int(game_id)\n",
    "\n",
    "        if game_id in already_scraped_ids or game_id in not_yet_played_ids or game_id in forfeited_game_ids:\n",
    "            continue\n",
    "        \n",
    "        # Attempt to get data, unless it hasn't been played - Log it as such, and move on\n",
    "        try:\n",
    "            home_df,away_df = create_home_and_away_simple_dataframe(game_id)\n",
    "        except ValueError as e:\n",
    "            not_yet_played_ids.add(game_id)\n",
    "            continue\n",
    "        except BadStatusCodeError as e:\n",
    "            bad_requests_counter +=1\n",
    "            if bad_requests_counter == 5:\n",
    "                raise Exception(\"5 bad requests...\")\n",
    "            continue\n",
    "        \n",
    "        # Transform home and away dataframes\n",
    "        home_df = home_df.reset_index().drop('level_1',axis = 1).rename(columns = {'level_0':\"Team\"})\\\n",
    "        .assign(Opponent = sub_dict['OPPONENT'].replace(\"@\",\"\").strip()).query(\"Player != 'Team'\")\\\n",
    "        .assign(Game_ID = game_id).copy()\n",
    "\n",
    "        away_df = away_df.reset_index().drop('level_1',axis = 1).rename(columns = {'level_0':'Team'.strip()})\\\n",
    "        .assign(Opponent = team).query(\"Player != 'Team'\")\\\n",
    "        .assign(Game_ID = game_id).copy()\n",
    "\n",
    "        final_df = pd.concat([home_df,away_df])\n",
    "        final_df['Game_Date'] = sub_dict['DATE']\n",
    "\n",
    "        master_df = pd.concat([master_df,final_df])\n",
    "        already_scraped_ids.add(game_id)\n",
    "        time_to_sleep = np.random.randint(7,14)\n",
    "\n",
    "        counter +=1\n",
    "        scrape_counter +=1\n",
    "        if counter == 25:\n",
    "            # Save every 25 iterations, just in case\n",
    "            master_df.assign(Game_ID = master_df.Game_ID.astype(int)).to_parquet('parquet_files/master_dataframe.gzip',compression='gzip')\n",
    "            print(master_df.Game_ID.nunique())\n",
    "            counter = 0\n",
    "        if scrape_counter >= 5:\n",
    "            quick_skip = False\n",
    "        \n",
    "        if not quick_skip:\n",
    "            # Sleep\n",
    "            time.sleep(time_to_sleep)\n",
    "        else:\n",
    "            time.sleep(2)\n",
    "\n",
    "    # Sleep\n",
    "    if not quick_skip:\n",
    "        time.sleep(np.random.randint(20,120))\n",
    "    else:\n",
    "        time.sleep(18)\n",
    "\n",
    "master_df.reset_index(drop=True).to_parquet('parquet_files/master_dataframe.gzip',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_parquet('parquet_files/master_dataframe.gzip',compression='gzip')\n",
    "print(master_df.Game_ID.nunique())\n",
    "\n",
    "with open('pickle_files/not_yet_played_games.pickle','wb') as f:\n",
    "    pickle.dump(not_yet_played_ids,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "788e49aa3fe5dd1af6a68397f1749d9e903e8595b7673a0aae7419ea668aa0b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
